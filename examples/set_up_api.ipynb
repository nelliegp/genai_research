{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5c98c-1c69-49b6-9398-be3e5d5d30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import open AI Library #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bfc5ad-3c1d-460c-9464-989271c50fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48283faf-4123-4782-8590-8a88753b6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# set api key which is obtained through open ai account\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "# set home directory\n",
    "HOME = \"/Users/nataliahelms/ai_seeding_effort_research/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e407b-67fe-4d89-9a8c-b789a3bdc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# set api key which is obtained through open ai account\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "# set home directory\n",
    "HOME = \"/Users/nataliahelms/ai_seeding_effort_research/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14fa4c-1d31-4728-87f6-df33a893c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Builing Completion API Call #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e79e4-a2f5-41fa-a13d-10879f4b647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a chat API call has two required inputs:\n",
    "    # 1. model: the name of the model you want to use (ex. gpt-3.5-turbo, gpt-4)\n",
    "    # 2. messages: a list of message objects where each object has two required fields:\n",
    "        # 1. role: the role of the messanger (system, user, assistant, or tool)\n",
    "        # 2. content: the content of the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864aa93-fe00-455d-81d4-efcef19783a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected model\n",
    "#MODEL = \"gpt-4\"\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# completion API call, specified as response (look at diff b/w chat.completions vs just completions)\n",
    "response = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a6e3e-db18-4d08-92fa-d677398323b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout out response\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfbae6-075a-4c37-802c-d53975670ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Understanding the Response #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc3108-4695-4b94-9303-e584f65e7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response object has a few fields:\n",
    "    # id: the ID of the request\n",
    "    # object: the type of object returned (e.g., chat.completion)\n",
    "    # created: the timestamp of the request\n",
    "    # model: the full name of the model used to generate the response\n",
    "    # usage: the number of tokens used to generate the replies, counting prompt, completion, and total\n",
    "    # choices: a list of completion objects (only one, unless you set n greater than 1)\n",
    "    # message: the message object generated by the model, with role and content\n",
    "    # finish_reason: the reason the model stopped generating text (either stop, or length if max_tokens limit was reached)\n",
    "    # index: the index of the completion in the list of choices\n",
    "# so we can extract just the reply by:\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
